{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proyecto 2 - Procesamiento de datos utilizando Apache Hive y Apache Zeppelin\n",
    "\n",
    "#### Análisis de logs de un web server\n",
    "\n",
    "![Webserver Logo](https://www.freepngimg.com/thumb/computer/58645-web-http-servers-computer-linux-apache-installation.png) \n",
    "\n",
    "Este proyecto demostrará lo fácil que es realizar análisis de logs de servidores web con Apache Hive.\n",
    "\n",
    "El análisis de logs de un servidor es un caso de uso ideal para Apache Hive.  Es una fuente de datos muy grande y común, y contiene un rico conjunto de información.  Hive le permite almacenar sus logs en archivos en disco de forma económica, a la vez que proporciona una forma rápida y sencilla de realizar análisis de datos sobre ellos. Le mostraremos cómo utilizar Apache Hive en logs de producción basados en texto del mundo real y aprovechar al máximo la potencia de esos datos.  Los datos de logs provienen de muchas fuentes, como servidores web, de archivos y de computación, logs de aplicaciones, contenido generado por el usuario, y pueden utilizarse para monitorizar servidores, mejorar la inteligencia de negocio y de clientes, y mucho más."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 1 - Descarga de archivos de datos que vamos a procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrar al directorio\n",
    "cd /home/dataengineer/files\n",
    "\n",
    "# Descargamos de la red los archivos que vamos a utilizar\n",
    "wget https://raw.githubusercontent.com/hivesample/sample/main/Web_log\n",
    "\n",
    "# Luego copiamos los archivos a HDFS\n",
    "hdfs dfs -copyFromLocal Web_log /user/dataengineer/filesdata\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2 - Iniciar Hadoop, Hive y Zeppelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos el directorio donde realizamos la instalación de hadoop e ingresamos\n",
    "cd /home/dataengineer/hadoop/hadoop-3.3.2/\n",
    "\n",
    "# Iniciamos el sistema de archivos distribuidos\n",
    "sbin/start-dfs.sh\n",
    "\n",
    "# Iniciamos yarn\n",
    "sbin/start-yarn.sh\n",
    "\n",
    "# Buscamos el directorio donde realizamos la instalacion de hive e ingresamos\n",
    "cd /home/dataengineer/apachehive/apache-hive-3.1.2-bin/\n",
    "\n",
    "# Ejecutamos hive\n",
    "bin/hiveserver2\n",
    "\n",
    "# Buscamos el directorio donde realizamos la instalacion de zeppelin e ingresamos\n",
    "cd /home/dataengineer/zeppelin/zeppelin-0.10.1-bin-all/ \n",
    "\n",
    "# Ejecutamos zeppelin\n",
    "bin/zeppelin-daemon.sh start\n",
    "\n",
    "# Desde el navegador ingresamos a la interfaz gráfica de zeppelin\n",
    "https://localhost:8080/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3 - Configuración del intérprete Hive en la interfaz gráfica de Apache Zeppelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto lo explicamos en el Proyecto 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4 - Creación de tablas y carga de datos en el notebook Zepellin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la tabla 'apachelog'\n",
    "\n",
    "%Hive\n",
    "\n",
    "CREATE TABLE apachelog (\n",
    "HOST STRING,  \n",
    "IDENTITY STRING,  \n",
    "WUSER STRING,  \n",
    "WTIME STRING,  \n",
    "request STRING,  \n",
    "status STRING,  \n",
    "SIZE STRING) \n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES \n",
    "(\"input.regex\" = \"([^ ]*) ([^ ]*) ([^ ]*) (-|\\\\[[^\\\\]]*\\\\]) ([^ \\\"]*|\\\"[^\\\"]*\\\") (-|[0-9]*) (-|[0-9]*)?\")\n",
    "STORED AS TEXTFILE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "\n",
    "%Hive\n",
    "\n",
    "LOAD DATA INPATH '/user/dataengineer/filesdata/Web_log' INTO TABLE apachelog;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanzamos una consulta para verificar que los datos se hayan cargado correctamente\n",
    "\n",
    "%Hive\n",
    "\n",
    "SELECT * FROM apachelog;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estás familiarizado con los servidores web, reconocerás de que se habla en [Common Log Format](https://www.w3.org/Daemon/User/Config/Logging.html#common-logfile-format). Los campos son:\n",
    "\n",
    "_remotehost rfc931 authuser [date] \"request\" status bytes_\n",
    "\n",
    "| campo         | significado                                                                                                  |\n",
    "| ------------- | -------------------------------------------------------------------------------------------------------------|\n",
    "| _remotehost_  | Nombre de host remoto (o número IP si el nombre de host DNS no está disponible).                             |\n",
    "| _rfc931_      | El logname remoto del usuario. Este campo no nos interesa.                                                   |\n",
    "| _authuser_    | El username del usuario remoto, autenticado por el servidor HTTP. Este campo no nos interesa.                |\n",
    "| _[date]_      | Fecha y hora de la petición.                                                                                 |\n",
    "| _\"request\"_   | La petición, exactamente como vino del navegador o del cliente.                                              |\n",
    "| _status_      | El código de estado HTTP que el servidor envió de vuelta al cliente.                                         |\n",
    "| _bytes_       | El número de bytes (`Content-Length`) transferidos al cliente.                                               |\n",
    "\n",
    "A continuación, tenemos que dividirlo en columnas individuales. Usaremos la función especial incorporada [regexp\\_extract()]\n",
    "para realizar el análisis. Esta función compara una columna con una expresión regular con uno o más [grupos de captura](https://www.tutorialspoint.com/scala/scala_regular_expressions.htm) y le permite extraer uno de los grupos coincidentes. Utilizaremos una expresión regular para cada campo que deseemos extraer.\n",
    "\n",
    "Sitio web donde existe material para comenzar a estudiar las Expresiones regulares (https://www.tutorialspoint.com/scala/scala_regular_expressions.htm). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 5 - Análisis de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estadísticas sobre el tamaño de los contenidos\n",
    "\n",
    "Calculemos algunas estadísticas sobre el tamaño de los contenidos devueltos por el servidor web. En concreto, nos gustaría saber cuál es el tamaño medio, mínimo y máximo de los contenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select \n",
    "min(size) AS Minimum,\n",
    "max(size) AS Maximum,\n",
    "avg(size) AS Average\n",
    "from apachelog;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HTTP Status Analisis\n",
    "\n",
    "A continuación, vamos a ver los valores de status que aparecen en el log. Queremos saber qué valores de status aparecen en los datos y cuántas veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select \n",
    "status,\n",
    "count(status) as countbystatus\n",
    "from apachelog group by status order by status asc;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hosts Frecuentes\n",
    "\n",
    "Veamos los hosts que han accedido al servidor con frecuencia. Al igual que con el análisis del código de respuesta \n",
    "\n",
    "A continuación, filtramos el resultado en función del recuento de accesos de cada host.  A continuación, seleccionamos la columna 'host' y mostramos algunos elementos del resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select \n",
    "host, \n",
    "count(host)  as CountofHost \n",
    "from apachelog group by Host order by CountofHost desc;  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top Paths\n",
    "\n",
    "Para el ejemplo final, encontraremos las top paths (URIs) en el log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select \n",
    "regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1) as path, \n",
    "count(regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1)) as Countofpath \n",
    "from apachelog group by regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1)  order by Countofpath desc;  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Las diez principales error paths\n",
    "\n",
    "¿Cuáles son los diez paths principales que no tienen el código de retorno 200?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select \n",
    "regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1) as path, \n",
    "count(regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1)) as Countofpath, \n",
    "status\n",
    "from apachelog \n",
    "where status != 200\n",
    "group by regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1),status\n",
    "order by Countofpath desc limit 10;  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Número de hosts únicos\n",
    "\n",
    "¿Cuántos hosts únicos hay en todo el log?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select\n",
    "distinct(Host)  as Host\n",
    "from apachelog; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select \n",
    "count(distinct(Host)) as CountofUniqueHost\n",
    "from apachelog; "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Número de hosts únicos diarios\n",
    "\n",
    "Como ejercicio avanzado, vamos a determinar el número de hosts únicos en todo el log día a día. Este cálculo nos dará el número de hosts únicos diarios. \n",
    "\n",
    "**Descripción de cada variable\n",
    "\n",
    "| column | explanation          |\n",
    "| ------ | -------------------- |\n",
    "| `host` | the host name        |\n",
    "| `day`  | the day of the month |\n",
    "\n",
    "\n",
    "| column  | explanation                                        |\n",
    "| ------- | -------------------------------------------------- |\n",
    "| `day`   | the day of the month                               |\n",
    "| `count` | the number of unique requesting hosts for that day |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Número de requests diarias por host único\n",
    "\n",
    "A continuación, vamos a determinar el número de peticiones por día.  Queremos una lista por día del mes en aumento y el promedio asociado de peticiones por host para ese día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "\n",
    "select\n",
    "host,\n",
    "count(request)  as NumberofRequest,\n",
    "split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0] as datelimited\n",
    "from \n",
    "apachelog group by split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0], Host order by split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0] asc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploración de los códigos de estado 404\n",
    "\n",
    "Vamos a profundizar y explorar los registros de estado de error 404. Todos hemos visto esas páginas web \"404 Not Found\". Los errores 404 se devuelven cuando el servidor no puede encontrar el recurso (página u objeto) que el navegador o el cliente solicitó."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contando Códigos de Respuesta 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive \n",
    "\n",
    "select\n",
    "status,\n",
    "count(status) as countofstatus\n",
    "from apachelog where status = 404 group by status;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listado de las veinte principales paths con código de respuesta 404\n",
    "\n",
    "Imprime una lista de las veinte paths que generan más errores 404.\n",
    "\n",
    "*Recuerde, las paths principales deben estar ordenadas*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select\n",
    "regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1) as path, \n",
    "status,\n",
    "count(status)\n",
    "from apachelog where status = 404 group by status, regexp_extract(request, '^.*\"\\\\w+\\\\s+([^\\\\s]+)\\\\s+HTTP.*\"', 1) order by count(status) desc limit 20;\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de los errores 404 por día\n",
    "\n",
    "Imprimir gráfico de los códigos de respuesta 404 por día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select\n",
    "status,\n",
    "count(status) as countofstatus,\n",
    "split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0] as datelimited\n",
    "from \n",
    "apachelog where status = 404\n",
    "group by split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0], status order by split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0];\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los cinco días con más errores 404\n",
    "\n",
    "¿cuáles son los cinco días con más errores 404 y el número correspondiente de errores 404?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%Hive\n",
    "\n",
    "select\n",
    "status,\n",
    "count(status) as countofstatus,\n",
    "split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0] as datelimited\n",
    "from \n",
    "apachelog where status = 404\n",
    "group by split(regexp_extract(WTIME, '^.*\\\\[(\\\\d\\\\d/\\\\w{3}/\\\\d{4}:\\\\d{2}:\\\\d{2}:\\\\d{2} -\\\\d{4})]', 1),':')[0], status order by count(status) desc limit 5;"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
